"""Tests for the AIInsightsPanel component."""

from datetime import datetime, timedelta, timezone
from unittest.mock import MagicMock, Mock, patch
from uuid import uuid4

import pytest
from textual.app import App, ComposeResult
from textual.widgets import Button, Select, Static

from gke_log_processor.ai.analyzer import QueryResponse
from gke_log_processor.ai.summarizer import (
    KeyInsight,
    LogSummaryReport,
    TimeWindowSize,
    TimeWindowSummary,
    TrendAnalysis,
    TrendDirection,
)
from gke_log_processor.core.models import (
    AIAnalysisResult,
    DetectedPattern,
    LogEntry,
    LogLevel,
    PatternType,
    SeverityLevel,
)
from gke_log_processor.ui.components.ai_insights_panel import AIInsightsPanel


@pytest.fixture
def sample_analysis_result():
    """Create sample AI analysis result."""
    patterns = [
        DetectedPattern(
            pattern="Database connection timeout",
            confidence=0.95,
            severity=SeverityLevel.HIGH,
            type=PatternType.ERROR_PATTERN,
            occurrence_count=15,
            affected_pods=["db-pod-1", "db-pod-2"],
            first_seen=datetime.now(timezone.utc),
            last_seen=datetime.now(timezone.utc),
            recommendation="Check database server health and network connectivity"
        ),
        DetectedPattern(
            pattern="High memory usage",
            confidence=0.80,
            severity=SeverityLevel.MEDIUM,
            type=PatternType.PERFORMANCE_ISSUE,
            occurrence_count=8,
            affected_pods=["app-pod-1"],
            first_seen=datetime.now(timezone.utc),
            last_seen=datetime.now(timezone.utc),
            recommendation="Consider increasing memory limits"
        )
    ]

    return AIAnalysisResult(
        overall_severity=SeverityLevel.HIGH,
        confidence_score=0.88,
        detected_patterns=patterns,
        top_error_messages=["Connection timeout", "Memory limit exceeded"],
        log_entries_analyzed=1500,
        time_window_start=datetime.now(timezone.utc) - timedelta(hours=1),
        time_window_end=datetime.now(timezone.utc),
        error_rate=0.12,
        warning_rate=0.25,
        analysis_timestamp=datetime.now(timezone.utc)
    )


@pytest.fixture
def sample_summary_report():
    """Create sample summary report."""
    insights = [
        KeyInsight(
            title="High Error Rate",
            description="Error rate increased by 30% in the last hour",
            confidence=0.92,
            severity=SeverityLevel.HIGH,
            affected_windows=[datetime.now(timezone.utc) - timedelta(hours=1), datetime.now(timezone.utc)]
        )
    ]

    trends = [
        TrendAnalysis(
            metric_name="Error Rate",
            direction=TrendDirection.INCREASING,
            change_percentage=30.5,
            confidence=0.85,
            time_window=TimeWindowSize.ONE_HOUR,
            recommendation="Investigate recent deployments"
        )
    ]

    window_summaries = [
        TimeWindowSummary(
            start_time=datetime.now(timezone.utc),
            end_time=datetime.now(timezone.utc),
            window_size=TimeWindowSize.ONE_HOUR,
            log_count=500,
            error_count=25,
            warning_count=50,
            overall_severity=SeverityLevel.MEDIUM,
            summary_text="High activity period with increased errors"
        )
    ]

    return LogSummaryReport(
        time_range_start=datetime.now(timezone.utc),
        time_range_end=datetime.now(timezone.utc),
        total_log_entries=1500,
        window_summaries=window_summaries,
        key_insights=insights,
        trend_analyses=trends,
        executive_summary="System experiencing elevated error rates",
        recommendations=["Scale up resources", "Check database health"],
        generation_timestamp=datetime.now(timezone.utc)
    )


@pytest.fixture
def sample_query_response():
    """Create sample query response."""
    return QueryResponse(
        request_id=uuid4(),
        question="What are the main issues?",
        answer="The main issues are database connectivity problems and memory constraints.",
        confidence_score=0.87,
        sources_analyzed=1200,
        related_patterns=["Database timeout", "Memory pressure"],
        suggested_followups=["How can we fix the database issues?", "What's causing memory pressure?"],
        query_duration_seconds=1.8
    )


class AIInsightsPanelTestApp(App):
    """Test app for component testing."""

    def __init__(self, widget):
        super().__init__()
        self.widget = widget

    def compose(self) -> ComposeResult:
        yield self.widget


class TestAIInsightsPanel:
    """Test cases for AIInsightsPanel."""

    @pytest.fixture
    def insights_panel(self):
        """Create an AIInsightsPanel instance for testing."""
        return AIInsightsPanel()

    @pytest.fixture
    def app_with_insights_panel(self, insights_panel):
        """Create test app with insights panel."""
        return AIInsightsPanelTestApp(insights_panel)

    def test_initialization(self, insights_panel):
        """Test widget initialization."""
        assert insights_panel.analysis_result is None
        assert insights_panel.summary_report is None
        assert insights_panel.query_response is None
        assert insights_panel.display_mode == "overview"
        assert insights_panel.auto_refresh is True

    def test_reactive_attributes(self, insights_panel, sample_analysis_result):
        """Test reactive attribute updates."""
        insights_panel.analysis_result = sample_analysis_result
        assert insights_panel.analysis_result == sample_analysis_result

        insights_panel.display_mode = "patterns"
        assert insights_panel.display_mode == "patterns"

        insights_panel.auto_refresh = False
        assert insights_panel.auto_refresh is False

    @pytest.mark.asyncio
    async def test_compose_structure(self, app_with_insights_panel):
        """Test widget composition and structure."""
        async with app_with_insights_panel.run_test() as pilot:
            insights_panel = pilot.app.widget

            # Test for header components
            header = insights_panel.query_one(".insights-header")
            assert header is not None

            # Test for controls
            controls = insights_panel.query_one(".insights-controls")
            assert controls is not None

            # Test for content display
            content = insights_panel.query_one("#insights-display", Static)
            assert content is not None

    def test_update_analysis(self, insights_panel, sample_analysis_result):
        """Test updating analysis results."""
        logs = [Mock()]
        with patch.object(insights_panel, '_update_display'):
            insights_panel.update_analysis(sample_analysis_result, logs)

        assert insights_panel.analysis_result == sample_analysis_result
        assert insights_panel._current_logs == logs

    def test_update_summary(self, insights_panel, sample_summary_report):
        """Test updating summary report."""
        with patch.object(insights_panel, '_update_display'):
            insights_panel.update_summary(sample_summary_report)
        assert insights_panel.summary_report == sample_summary_report

    def test_update_query_response(self, insights_panel, sample_query_response):
        """Test updating query response."""
        with patch.object(insights_panel, 'query_one') as mock_query:
            mock_select = Mock()
            mock_query.return_value = mock_select

            insights_panel.update_query_response(sample_query_response)
            assert insights_panel.query_response == sample_query_response
            assert insights_panel.display_mode == "query"

    def test_clear_insights(self, insights_panel, sample_analysis_result):
        """Test clearing all insights."""
        insights_panel.analysis_result = sample_analysis_result
        with patch.object(insights_panel, '_update_display'):
            insights_panel.clear_insights()

        assert insights_panel.analysis_result is None
        assert insights_panel.summary_report is None
        assert insights_panel.query_response is None

    def test_render_overview_no_data(self, insights_panel):
        """Test overview rendering with no data."""
        content = insights_panel._render_overview()
        assert "No Analysis Available" in content
        assert "Run analysis" in content

    def test_render_overview_with_data(self, insights_panel, sample_analysis_result):
        """Test overview rendering with analysis data."""
        insights_panel.analysis_result = sample_analysis_result
        content = insights_panel._render_overview()

        assert "Overall Status" in content
        assert "High" in content  # Severity value is formatted as "High" not "HIGH"
        assert "Key Metrics" in content
        assert "Pattern Summary" in content

    def test_render_patterns_no_data(self, insights_panel):
        """Test patterns rendering with no data."""
        content = insights_panel._render_patterns()
        assert "No Patterns Detected" in content

    def test_render_patterns_with_data(self, insights_panel, sample_analysis_result):
        """Test patterns rendering with pattern data."""
        insights_panel.analysis_result = sample_analysis_result
        content = insights_panel._render_patterns()

        assert "Detected Patterns" in content
        assert "Database connection timeout" in content
        assert "High memory usage" in content
        assert "Error_Pattern Patterns" in content  # Pattern type enum values are used directly
        assert "Performance_Issue Patterns" in content  # Pattern type enum values are used directly

    def test_render_summary_no_data(self, insights_panel):
        """Test summary rendering with no data."""
        content = insights_panel._render_summary()
        assert "No Summary Available" in content

    def test_render_summary_with_data(self, insights_panel, sample_summary_report):
        """Test summary rendering with summary data."""
        insights_panel.summary_report = sample_summary_report
        content = insights_panel._render_summary()

        assert "Log Summary Report" in content
        assert "Analysis Period" in content
        assert "Executive Summary" in content
        assert "Key Insights" in content

    def test_render_recommendations_no_data(self, insights_panel):
        """Test recommendations rendering with no data."""
        content = insights_panel._render_recommendations()
        assert "No Recommendations Available" in content

    def test_render_recommendations_with_data(self, insights_panel, sample_analysis_result, sample_summary_report):
        """Test recommendations rendering with data."""
        insights_panel.analysis_result = sample_analysis_result
        insights_panel.summary_report = sample_summary_report
        content = insights_panel._render_recommendations()

        assert "AI Recommendations" in content
        assert "Check database health" in content  # Updated to match actual recommendation text

    def test_render_query_results_no_data(self, insights_panel):
        """Test query results rendering with no data."""
        content = insights_panel._render_query_results()
        assert "No Query Results" in content

    def test_render_query_results_with_data(self, insights_panel, sample_query_response):
        """Test query results rendering with data."""
        insights_panel.query_response = sample_query_response
        content = insights_panel._render_query_results()

        assert "AI Query Response" in content
        assert "What are the main issues?" in content or "database connectivity problems" in content
        assert "Related Patterns" in content
        assert "Suggested Follow-ups" in content

    def test_analyze_button_functionality(self, insights_panel):
        """Test analyze button functionality."""
        with patch.object(insights_panel, 'post_message') as mock_post, \
                patch.object(insights_panel, 'query_one') as mock_query:

            # Mock the select widget
            mock_select = Mock()
            mock_select.value = "comprehensive"
            mock_query.return_value = mock_select

            # Mock button event
            mock_button = Mock()
            mock_button.id = "analyze-button"
            event = Mock()
            event.button = mock_button

            insights_panel.on_button_pressed(event)

            # Should post analysis requested message
            mock_post.assert_called_once()

    def test_query_button_functionality(self, insights_panel):
        """Test query button functionality."""
        with patch.object(insights_panel, 'post_message') as mock_post:
            # Mock button event
            mock_button = Mock()
            mock_button.id = "query-button"
            event = Mock()
            event.button = mock_button

            insights_panel.on_button_pressed(event)

            # Should post query requested message
            mock_post.assert_called_once()

    @pytest.mark.asyncio
    async def test_display_mode_select(self, app_with_insights_panel):
        """Test display mode selection."""
        async with app_with_insights_panel.run_test() as pilot:
            insights_panel = pilot.app.widget

            # Change display mode
            mode_select = insights_panel.query_one("#display-mode-select", Select)
            mode_select.value = "patterns"

            # Should update display mode
            if hasattr(insights_panel, '_update_display'):
                insights_panel._update_display()

    @pytest.mark.asyncio
    async def test_analysis_type_select(self, app_with_insights_panel):
        """Test analysis type selection."""
        async with app_with_insights_panel.run_test() as pilot:
            insights_panel = pilot.app.widget

            # Change analysis type
            type_select = insights_panel.query_one("#analysis-type-select", Select)
            type_select.value = "quick"

            # Should be available for analysis requests
            assert type_select.value == "quick"

    def test_message_classes_exist(self, insights_panel):
        """Test that message classes are properly defined."""
        # Test message classes exist and are instantiable
        analysis_msg = insights_panel.AnalysisRequested("comprehensive")
        assert analysis_msg.analysis_type == "comprehensive"

        query_msg = insights_panel.QueryRequested("test question")
        assert query_msg.question == "test question"

        rec_msg = insights_panel.RecommendationSelected("test recommendation")
        assert rec_msg.recommendation == "test recommendation"

    def test_update_display_method_exists(self, insights_panel):
        """Test that update display method exists and is callable."""
        assert hasattr(insights_panel, '_update_display')
        assert callable(getattr(insights_panel, '_update_display'))

        # Should not crash when called with proper mocking
        with patch.object(insights_panel, 'query_one') as mock_query:
            mock_query.return_value = Mock()
            try:
                insights_panel._update_display()
                success = True
            except Exception:
                success = False
        assert success

    def test_reactive_attributes_exist(self, insights_panel):
        """Test that reactive attributes exist and can be accessed."""
        # Test that reactive attributes are properly defined
        assert hasattr(insights_panel, 'analysis_result')
        assert hasattr(insights_panel, 'summary_report')
        assert hasattr(insights_panel, 'query_response')
        assert hasattr(insights_panel, 'display_mode')
        assert hasattr(insights_panel, 'auto_refresh')

    def test_severity_level_formatting(self, insights_panel):
        """Test severity level formatting in overview."""
        # Test with mock analysis result
        mock_result = Mock()
        mock_result.overall_severity = SeverityLevel.CRITICAL
        mock_result.confidence_score = 0.95
        mock_result.log_entries_analyzed = 1000
        mock_result.error_rate = 0.15
        mock_result.warning_rate = 0.30
        mock_result.analysis_duration_seconds = 3.2
        mock_result.detected_patterns = []
        mock_result.top_error_messages = []
        mock_result.recommendations = []

        insights_panel.analysis_result = mock_result
        content = insights_panel._render_overview()

        assert "ðŸš¨" in content  # Critical emoji
        assert "CRITICAL" in content.upper()

    def test_confidence_display(self, insights_panel, sample_analysis_result):
        """Test confidence score display formatting."""
        insights_panel.analysis_result = sample_analysis_result
        content = insights_panel._render_overview()

        # Should show confidence as percentage
        assert "88.0%" in content or "Confidence" in content

    def test_pattern_grouping(self, insights_panel, sample_analysis_result):
        """Test pattern grouping by type in patterns view."""
        insights_panel.analysis_result = sample_analysis_result
        content = insights_panel._render_patterns()

        # Should group patterns by type
        assert "Error_Pattern Patterns" in content  # Pattern type enum values are used directly
        assert "Performance_Issue Patterns" in content  # Pattern type enum values are used directly

    def test_recommendation_prioritization(self, insights_panel):
        """Test recommendation prioritization logic."""
        # Create mock recommendations with different priority keywords
        mock_analysis = Mock()
        mock_analysis.recommendations = [
            "Consider upgrading memory",
            "Immediately restart the service",
            "You may want to check logs"
        ]
        mock_summary = Mock()
        mock_summary.recommendations = ["Monitor disk usage"]

        insights_panel.analysis_result = mock_analysis
        insights_panel.summary_report = mock_summary
        content = insights_panel._render_recommendations()

        assert "Immediate Action Required" in content or "AI Recommendations" in content

    def test_empty_data_handling(self, insights_panel):
        """Test handling of empty or None data."""
        # Test with None values
        insights_panel.analysis_result = None
        insights_panel.summary_report = None
        insights_panel.query_response = None

        # Should not crash
        overview = insights_panel._render_overview()
        patterns = insights_panel._render_patterns()
        summary = insights_panel._render_summary()
        recommendations = insights_panel._render_recommendations()
        query_results = insights_panel._render_query_results()

        assert all("No" in content for content in [overview, patterns, summary, recommendations, query_results])

    def test_large_number_formatting(self, insights_panel):
        """Test formatting of large numbers in displays."""
        mock_result = Mock()
        mock_result.log_entries_analyzed = 1_500_000
        mock_result.overall_severity = SeverityLevel.LOW
        mock_result.confidence_score = 0.75
        mock_result.error_rate = 0.05
        mock_result.warning_rate = 0.10
        mock_result.analysis_duration_seconds = 1.5
        mock_result.detected_patterns = []
        mock_result.top_error_messages = []
        mock_result.recommendations = []

        insights_panel.analysis_result = mock_result
        content = insights_panel._render_overview()

        # Should format large numbers with commas
        assert "1,500,000" in content or "1500000" in content
